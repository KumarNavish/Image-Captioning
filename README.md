This Project is a part of our real time Video Caption Generation and its subsequent Text-to-Speech Translation. 
Aim of above project is to help visually impaired People in navigation with the help of __AI__.
# Image-Captioning
This Repo contains __pytorch__ implementation of Image captioning using __Bidirectional LSTMs with Soft Attention and Language Modelling as Stanford CoreNLP__.

__Dataset Used__  : MSCOCO (To use COCO Dataset please download all dependencies namely pycocotools and pycocoevalcap)

__Note :__  There are few bugs present in these dependencies which have to debugged,  I have already debugged them but due to Copyright issues i cannot upload here.

__Loss metrics Used__: 
* 4-gram BLUE 
* METEOR
* ROUGE_L
* CIDEr  scores 
